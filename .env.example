# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=your-password

# Vector Store Configuration
VECTOR_STORE_TYPE=pgvector

# LLM Provider Selection ("azure", "huggingface", "vllm", "openai", "gemini")
LLM_PROVIDER=azure

# Azure OpenAI Service Settings
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-3-small

# LLM Settings
LLM_TEMPERATURE=0.0
MAX_TOKENS=20480

# Azure Document Intelligence (PDF Processing)
PDF_PROCESSOR_TYPE=azure_di
AZURE_DI_ENDPOINT=https://your-di-resource.cognitiveservices.azure.com/
AZURE_DI_API_KEY=your-di-api-key
AZURE_DI_MODEL=prebuilt-layout
SAVE_MARKDOWN=false
MARKDOWN_OUTPUT_DIR=output/markdown

# LangSmith Tracing (Optional)
# Set to false by default to avoid rate limits
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=RAG Project
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Hugging Face Local LLM Settings (used when LLM_PROVIDER=huggingface)
HF_MODEL_ID=tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3
HF_EMBEDDING_MODEL_ID=intfloat/multilingual-e5-large
HF_DEVICE=cuda
HF_LOAD_IN_4BIT=true
HF_LOAD_IN_8BIT=false
HF_MAX_NEW_TOKENS=2048
HF_TEMPERATURE=0.0
HF_TOP_K=50
HF_TOP_P=0.9

# VLLM Server Settings (used when LLM_PROVIDER=vllm)
# Example endpoint: https://your-tunnel.loca.lt/v1 or http://localhost:8000/v1
VLLM_ENDPOINT=https://your-tunnel.loca.lt/v1
VLLM_TEMPERATURE=0.0
VLLM_TOP_P=0.7
VLLM_TOP_K=5
VLLM_MIN_P=0.0
VLLM_MAX_TOKENS=4096
VLLM_REASONING_EFFORT=medium
VLLM_TIMEOUT=60

# Advanced RAG Settings (Optional)
COLLECTION_NAME=documents
FINAL_K=5
VECTOR_SEARCH_K=3
KEYWORD_SEARCH_K=3
CONFIDENCE_THRESHOLD=0.2
