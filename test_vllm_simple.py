#!/usr/bin/env python3
"""
test_vllm_simple.py
===================
ã‚·ãƒ³ãƒ—ãƒ«ãªVLLMæ¥ç¶šãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.rag.config import Config
from src.rag.vllm_client import VLLMClient, VLLMChatClient


def test_vllm_connection():
    """VLLMæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("VLLM Simple Connection Test")
    print("=" * 60)

    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    config = Config()

    print(f"LLM_PROVIDER: {config.llm_provider}")
    print(f"VLLM_ENDPOINT: {config.vllm_endpoint}")

    if not config.vllm_endpoint:
        print("\nâŒ VLLM_ENDPOINT is not configured")
        return False

    print(f"Temperature: {config.vllm_temperature}")
    print(f"Max Tokens: {config.vllm_max_tokens}")
    print(f"Timeout: {config.vllm_timeout}s")
    print("-" * 60)

    try:
        # VLLMClientã‚’åˆæœŸåŒ–
        client = VLLMClient(
            endpoint=config.vllm_endpoint,
            temperature=config.vllm_temperature,
            top_p=config.vllm_top_p,
            top_k=config.vllm_top_k,
            min_p=config.vllm_min_p,
            max_tokens=config.vllm_max_tokens,
            reasoning_effort=config.vllm_reasoning_effort,
            timeout=config.vllm_timeout
        )

        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        test_prompt = "ã“ã‚“ã«ã¡ã¯ã€‚1ã‹ã‚‰5ã¾ã§æ•°ãˆã¦ãã ã•ã„ã€‚"
        print(f"\n[Test Prompt]: {test_prompt}")
        print("[Sending request to VLLM server...]")

        # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬
        start_time = time.time()
        response = client.invoke(test_prompt)
        elapsed_time = time.time() - start_time

        print(f"\nâœ… Success! (Response time: {elapsed_time:.2f}s)")
        if hasattr(response, "content"):
            print(f"[Response]:\n{response.content}")
        else:
            print(f"[Response]:\n{response}")

        return True

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_vllm_chat_client():
    """VLLMChatClient ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("VLLMChatClient Test")
    print("=" * 60)

    config = Config()

    try:
        # VLLMChatClientã‚’åˆæœŸåŒ–
        client = VLLMChatClient(
            endpoint=config.vllm_endpoint,
            temperature=config.vllm_temperature,
            top_p=config.vllm_top_p,
            top_k=config.vllm_top_k,
            min_p=config.vllm_min_p,
            max_tokens=100,  # çŸ­ã„å¿œç­”ã§æ¸¬å®š
            reasoning_effort=config.vllm_reasoning_effort,
            timeout=config.vllm_timeout
        )

        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        test_prompt = "Pythonã¨ã¯ä½•ã§ã™ã‹ï¼Ÿä¸€æ–‡ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        print(f"\n[Test Prompt]: {test_prompt}")

        start_time = time.time()
        response = client.invoke(test_prompt)
        elapsed_time = time.time() - start_time

        # ChatModeläº’æ›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯
        if hasattr(response, 'content'):
            print(f"âœ… Response has content attribute")
            print(f"[Response]: {response.content}")
            print(f"(Response time: {elapsed_time:.2f}s)")
        else:
            print(f"âŒ Response doesn't have content attribute")
            print(f"[Raw Response]: {response}")

        return True

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("Starting VLLM tests...")

    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    result1 = test_vllm_connection()

    # ChatClientãƒ†ã‚¹ãƒˆ
    result2 = test_vllm_chat_client()

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("Test Results:")
    print(f"  Connection Test: {'âœ… PASSED' if result1 else 'âŒ FAILED'}")
    print(f"  ChatClient Test: {'âœ… PASSED' if result2 else 'âŒ FAILED'}")

    if result1 and result2:
        print("\nğŸ‰ All tests passed! VLLM is working correctly.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the configuration.")
    print("=" * 60)
